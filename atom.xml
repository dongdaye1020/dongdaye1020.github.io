<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>皮卡丘去哪了</title>
  
  <subtitle>寻找皮卡丘ing</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://dzrx1020.com/"/>
  <updated>2018-08-01T08:31:45.456Z</updated>
  <id>http://dzrx1020.com/</id>
  
  <author>
    <name>Felix Dong</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>推荐系统实战（1）：什么是好的推荐系统</title>
    <link href="http://dzrx1020.com/2018/08/01/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98%EF%BC%881%EF%BC%89%EF%BC%9A%E4%BB%80%E4%B9%88%E6%98%AF%E5%A5%BD%E7%9A%84%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
    <id>http://dzrx1020.com/2018/08/01/推荐系统实战（1）：什么是好的推荐系统/</id>
    <published>2018-08-01T08:28:09.000Z</published>
    <updated>2018-08-01T08:31:45.456Z</updated>
    
    <content type="html"><![CDATA[<p><strong>前言：</strong> 本文是我在学习《推荐系统实战》以及相关推荐系统知识时的心得体会，仅供学习交流使用。</p><h2 id="一、什么是推荐系统？"><a href="#一、什么是推荐系统？" class="headerlink" title="一、什么是推荐系统？"></a>一、什么是推荐系统？</h2><p>在信息过载的时代，用户周围充斥这大量的信息，想要从中找到自己感兴趣的信息十分困难；同样的，对于信息制造者，让自己生产的信息脱颖而出，找到感兴趣的用户也是一件困难的事。  </p><p><strong>推荐系统，从本质上讲，就是自动联系用户与物品的工具，它可以帮助用户找到感兴趣的物品，也可将信息推送给对其感兴趣的用户。</strong> </p><p>推荐系统的价值则在于发掘长尾物品的价值，因为在传统的销售观念中，80%的销售额来源于20%的商品，主流商品代表了绝大多数用户的需求，而长尾商品往往代表了小部分人的需求，将长尾物品的商业价值最大化，就是推荐系统的价值所在。  </p><p>具体的推荐系统的实现，则是寻找恰当的桥梁将用户与物品相联系，常见的桥梁有社交、用户历史兴趣、物品自有属性、用户个人属性等。</p><h2 id="二、推荐系统常见的应用场景有哪些？"><a href="#二、推荐系统常见的应用场景有哪些？" class="headerlink" title="二、推荐系统常见的应用场景有哪些？"></a>二、推荐系统常见的应用场景有哪些？</h2><p>在互联网的各类网站中都有推荐系统的应用，尽管使用的推荐技术、应用的业务场景不同，但推荐系统应用的构成基本有如下三要素：<strong>前端展示页面、后端日志系统、推荐策略组合</strong>。  </p><p>例如在电子商务中，个性化推荐应用通常包括：用户历史兴趣推荐、用户社交推荐以及商品打包销售推荐；当然在视频电影网站、音乐电台网站、社交网络、个性化阅读、基于位置的服、个性化广告以及个性化邮件等领域都有所应用。其中音乐领域比较特殊，具有很多独特性：  </p><ul><li>物品空间大（相对于视频和书）</li><li>用户消费代价很小（时间上、经济上）</li><li><strong>物品重用率很高</strong></li><li><strong>用户使用充满激情（一个用户回听很多歌）</strong></li><li><strong>上下文相关（用户的处境影响听歌的选择）</strong></li><li>高度社会化（分享给朋友）</li><li>很多播放列表</li><li>次序很重要（用户播放是有次序的）</li></ul><h2 id="三、什么是好的推荐系统？"><a href="#三、什么是好的推荐系统？" class="headerlink" title="三、什么是好的推荐系统？"></a>三、什么是好的推荐系统？</h2><p>一个好的推荐系统往往是三方共赢的，对于用户方而言，可以找到更多自己真正感兴趣的物品；对于物品提供者而言，发掘了长尾商品的价值，获得了更高的商业价值；对于推荐系统而言，一个好的用户交互方式，能让推荐系统本身收集到更好的用户反馈，从而去提高推荐质量。好的推荐系统不仅仅能准确预测用户的行为，而且要拓展用户的视野，帮助其发现可能回感兴趣的商品。  </p><p>如何评价一个推荐系统的好坏呢？一是选择合适的实验方法，二是选择合适的评价指标。  </p><h3 id="1、评价的方法；"><a href="#1、评价的方法；" class="headerlink" title="1、评价的方法；"></a>1、评价的方法；</h3><p>常用的评价方法包括离线测试、用户调查以及在线测试。<br><strong>离线测试</strong>一般包括一下几个步骤：</p><ol><li>通过日志系统提取用户行为数据，按照一定格式生成标准的数据集；</li><li>将数据集划分为训练集和测试集；</li><li>在训练集上训练推荐模型，并在测试集上进行预测；</li><li>通过选择的评价指标对在测试集上的预测结果进行评价。<br>优缺点如下：<br><img src="http://pb0xohu5g.bkt.clouddn.com/18-8-1/81939853.jpg" alt="">  </li></ol><p><strong>用户调查</strong>就好比分层抽样+用户问卷调查的结合，具体的就是召集一批真实用户（注意用户群分布情况：年龄、性别、活活跃度），完成一些指定的任务后，询问一些设计好的问题，最后通过分析其行为和回答，了解推荐系统的性能效果。优点是可以获得用户的主管感受指标、相对于在线测试风险低，缺点是代价大（用户群小的话没有统计意义）、设计双盲实验困难大。  </p><p><strong>在线实验</strong>就是AB测试，也就是按一定规则将用户随机分成几组，不同组用不同的算法策略，对比各个组的评价指标情况。其有优点是公平地获得实际在线的性能指标、商业指标，缺点是只有周期长的情况下，才能获得可靠的性能指标。此外，一个大型网站的系统十分复杂，从推荐结果到展示给用户，往往需要多层，这些层由不同的团队控制，所以设计的AB测试系统也会很复杂。此时，有一个原则十分重要，那就是<strong>切分流量</strong>，不同团队获得的AB测试流量应统一管理，不同层级的流量且是正交的。　　</p><h3 id="2、评价的基本指标；"><a href="#2、评价的基本指标；" class="headerlink" title="2、评价的基本指标；　　"></a>2、评价的基本指标；　　</h3><p>（１）用户满意度：通常该指标无法通过离线测试获得，往往通过用户调查、在线实验获得。可以通过购买率、点击率、用户停留页面时间等等指标度量；　<br>（２）预测准确度：可以通过离线方式获得。下面介绍常用的统计指标：　</p><ul><li>评分预测：RSME和MAE<br><br>误差平法和：<br><br><img src="http://pb0xohu5g.bkt.clouddn.com/18-8-1/95303537.jpg" alt=""><br><br>平均绝对误差：<br>　<br><img src="http://pb0xohu5g.bkt.clouddn.com/18-8-1/96019287.jpg" alt=""><br><br>RSME比MAE更加严格，在评分取整时，预测结果往往会降低MAE。<br><br>　　<br></li><li>ＴｏｐＮ推荐<br><br>召回率：<br><br><img src="http://pb0xohu5g.bkt.clouddn.com/18-8-1/29012340.jpg" alt="">　<br><br>精确率：<br><br><img src="http://pb0xohu5g.bkt.clouddn.com/18-8-1/57512783.jpg" alt="">　<br><br>TOPN推荐更符合实际的应用需求，因为推荐的主要目的是为了预测用户是否敢兴趣，而不是给出多少评分　<br><br>　<br><br>（３）覆盖率　<br><br>普通的覆盖率：　<br><br><img src="http://pb0xohu5g.bkt.clouddn.com/18-8-1/28198773.jpg" alt="">　<br><br>信息熵：　<br><br><img src="http://pb0xohu5g.bkt.clouddn.com/18-8-1/21638840.jpg" alt="">　<br><br>基尼系数：　<br><br><img src="http://pb0xohu5g.bkt.clouddn.com/18-8-1/9967551.jpg" alt="">　<br><br>普通的覆盖率过于粗略，信息熵和基尼系数则更为具有代表性。此外，基尼系数的实际含义可以理解为最不热门的产品占总数量的比例，所以其越小，代表的覆盖率越大，所以也可以用来衡量推荐系统是否具有马太效应。<br>　<br><br>（４）多样性　<br><br>多样性描述了用户推荐列表里商品之间的不相似性，故可以通过计算用户推荐列表里的物品相似性来计算　<br><br>单个用户的推荐列表的多样性：　<br><br><img src="http://pb0xohu5g.bkt.clouddn.com/18-8-1/6626584.jpg" alt="">　<br><br>所有用户的多样性　<br><br><img src="http://pb0xohu5g.bkt.clouddn.com/18-8-1/61148478.jpg" alt="">　<br><br>需要注意推荐系统的多样性也要符合用户的历史兴趣习惯，保持分布上的大致相同。　<br><br>　<br><br>（５）新颖性　<br><br>通俗地说，就是推荐一些用户没有听说过的商品，最简单的方式是过滤已经使用过的商品，另一种则是推荐平均热度较低的商品；<br><br>　<br><br>（６）惊喜度　<br><br>惊喜度没有公认的定义标准，基本意思是推荐了一个与用户历史兴趣没有关系的商品，但却很受用户欢迎。也就是在提高推荐满意度的同时，降低推荐结果的历史相似度；　<br><br>　<br><br>（７）信任度　<br><br>以用户信任的方式推荐商品，需要增加推荐的透明度（提供解释）；　<br><br>　<br><br>（８）实时性　<br><br>两个方面，一是根据用户的及时行为，更新新的推荐结果，二是将新上架的物品推荐给用户；<br><br>　<br><br>（９）健壮性　<br><br>防止作弊与用户攻击，例如刷单等行为提高商品热度。一是用使用代价较高的用户行为建模，二是对攻击行为进行识别过滤脏数据；　<br><br>　<br><br>（１０）商业目标　<br><br>利用推荐系统加快商业目标的实现；　<br><br>　<br><br>关于部分指标的总结：　<br><br><img src="http://pb0xohu5g.bkt.clouddn.com/18-8-1/61738871.jpg" alt="">　<br><br>对于离线实验的优化目标，往往是在给定覆盖率、多样性以及新颖性的条件下，最大化预测准确率。　<br><br>　<br><h3 id="3、与评价维度结合—更清楚推荐系统性能；"><a href="#3、与评价维度结合—更清楚推荐系统性能；" class="headerlink" title="3、与评价维度结合—更清楚推荐系统性能；　"></a>3、与评价维度结合—更清楚推荐系统性能；　<br></h3>分析的本质是对比，对比的常用方法就是纵向和横向。在实际评价中，往往会将这些指标与评价维度相结合，去评价在具体情况下推荐系统的优良性：　<br></li><li>用户维度：人口学特征、活跃度、新旧用户情况等；　<br></li><li>物品维度：物品的自有属性（分类特征）、流行度、平均分、新旧情况；　<br></li><li>时间维度：季节、工作日节假日、白天还是晚上；　<br><br>　<br><br>以上就是本文的全部内容，欢迎批评指正！　<br><br>　<br><br>　<br></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;前言：&lt;/strong&gt; 本文是我在学习《推荐系统实战》以及相关推荐系统知识时的心得体会，仅供学习交流使用。&lt;/p&gt;
&lt;h2 id=&quot;一、什么是推荐系统？&quot;&gt;&lt;a href=&quot;#一、什么是推荐系统？&quot; class=&quot;headerlink&quot; title=&quot;一、
      
    
    </summary>
    
      <category term="推荐系统" scheme="http://dzrx1020.com/categories/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
    
    
      <category term="推荐系统" scheme="http://dzrx1020.com/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
    
      <category term="推荐效果评价指标" scheme="http://dzrx1020.com/tags/%E6%8E%A8%E8%8D%90%E6%95%88%E6%9E%9C%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87/"/>
    
  </entry>
  
  <entry>
    <title>集成学习框架简介</title>
    <link href="http://dzrx1020.com/2018/07/28/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6%E7%AE%80%E4%BB%8B/"/>
    <id>http://dzrx1020.com/2018/07/28/集成学习框架简介/</id>
    <published>2018-07-28T01:51:43.000Z</published>
    <updated>2018-07-28T02:05:28.057Z</updated>
    
    <content type="html"><![CDATA[<p><strong>前言</strong>：以下内容主要是本人在学习台大林轩田机器学习技法课程中模型融合部分以及《统计学习方法》相关内容的学习心得，且不涉及公式推导和证明部分。  </p><hr><h2 id="1-集成学习的动机与框架"><a href="#1-集成学习的动机与框架" class="headerlink" title="1.集成学习的动机与框架"></a>1.集成学习的动机与框架</h2><h3 id="（1）为什么要用集成学习？"><a href="#（1）为什么要用集成学习？" class="headerlink" title="（1）为什么要用集成学习？"></a>（1）为什么要用集成学习？</h3><p>集成学习是通过构建和组合多个较弱的学习器，得到一个较强的模型，是因为这样做有两个优点：<br><strong>第一，cure underfitting</strong>（降低偏差）：有助于防止欠拟合，它把所有弱的学习器融合起来，能达到提取组合特征的功能（每一个弱的学习器相当于组合提取了一次特征），起到了feature transform的作用，可以得到较为复杂的模型;<br><strong>第二，cure overfitting</strong>（降低方差）：有助于防止过拟合，把所有学到的学习器进行组合，将可能过拟合与欠拟合的学习器进行中和，容易得到一个中庸的模型，防止过拟合。  </p><h3 id="（2）集成学习的框架简介"><a href="#（2）集成学习的框架简介" class="headerlink" title="（2）集成学习的框架简介"></a>（2）集成学习的框架简介</h3><p>按照集成学习组合策略方式的不同，可以将集成学习分为三类：<strong>uniform</strong>、<strong>non-uniform</strong>和<strong>conditional。</strong>（我们可以简单地理解为每人一票且同样重要、每人一票但要加权、看情况选择部分人加权投票）  </p><p>从集成学习的定义可以看出，我们需要两步，一是得到不同的学习器g(t)，二是使用策略组合得到的g(t)。我们称第二步的过程为blending，在g(t)已知的情况下，blending对应的分类如下：  </p><table><thead><tr><th>aggregation</th><th>blending</th></tr></thead><tbody><tr><td>uniform</td><td>voting/averaging</td></tr><tr><td>non-uniform</td><td>linear</td></tr><tr><td>conditional</td><td>stacking</td></tr></tbody></table><p>可以证明使用voting的blending策略组合g(t)可以得到更好的模型（主要是从期望角度证明了，平均组合后的G(t)可以降低模型的方差，能得到更加稳定的模型），而linear策略的本质则是通过线性变换达到feature transform的作用，stacking则是非线性变换（此策略可以得到更为复杂的模型，所以应该注意防止过拟合）。  </p><p>那么在g(t)未知的情况，如何才能得到不同的g(t)？<br>通常情况下，可以选取模型、设置不同的参数、不同的样本数据等方法获得。但通常情况下，我们只有一份数据集，此时可以借鉴统计学中boostrap思想，利用已知的样本数据，通过放回的重抽样方法，获得不同的样本数据集。  </p><p>回到集成学习的具体实现上，我们需要获得不同的g(t)，并使用策略进行组合，我们将这整个过程成为learing。使用不同blending策略，对应着不同的learing方法。  </p><p>接下来可以通过三种代表性的learing方法，来实现集成学习。 </p><hr><h2 id="2-集成学习的初阶实现"><a href="#2-集成学习的初阶实现" class="headerlink" title="2.集成学习的初阶实现"></a>2.集成学习的初阶实现</h2><table><thead><tr><th>aggregation</th><th>blending</th><th>learing</th></tr></thead><tbody><tr><td>uniform</td><td>voting/averaging</td><td>bagging</td></tr><tr><td>non-uniform</td><td>linear</td><td>boosting</td></tr><tr><td>conditional</td><td>stacking</td><td>Decision Tree</td></tr></tbody></table><h3 id="（1）bagging"><a href="#（1）bagging" class="headerlink" title="（1）bagging"></a>（1）bagging</h3><p>正如第一部分所讲的，bagging其实就是利用boostrap方法对数据集进行重抽样，获得多个数据集，以多个数据集为基础，训练得到多个学习器g(t)，最后通过平均化形成最终的模型，直观地讲，在回归问题上是对每个最终结果求平均，在分类问题上则是多数表决原则。由于只使用bagging一直方法的情况很少，故此处不再赘述。  </p><h3 id="（2）boosting"><a href="#（2）boosting" class="headerlink" title="（2）boosting"></a>（2）boosting</h3><p>boosting，顾名思义是通过迭代的方法不断提升组合模型的效果，也就是加法模型，最常见的就是adaboost。算法的一般步骤包括：<br>对于1,2,3,~,T轮迭代过程中,选择损失函数以及弱分类器g(t)后：<br>a.寻找能使损失函数最快降低的g(t)，及其对应的系数α；<br>b.更新加法模型后，再次进行a步骤。  </p><p>adaboost是用来解决二分类问题的，其损失函数为指数损失函数。通过每一轮模型的误分率来调整样本权重以获得下一步的新g(t)，并以此为基础来计算该轮g(t)的系数。  </p><p>按照李航老师的解释，可以将adaboost看成是<strong>损失函数是指数损失函数的前向分布算法</strong>(证明的话是先固定模型权重，证每轮更新的g(t)相等，然后再带入原式中，通过求偏导数，计算权重值)。 </p><p>按照林轩田老师的解释，可以将adaboost看成<strong>损失函数是指数损失、处理二分类问题的Gradient Boosting算法</strong>，这样的好处是可以方便引出下面的GBDT算法，此处的证明有两个个要点 ：  </p><p><strong>a.</strong> 第t+1轮的所有样本的权重和Z与前t轮模型的损失函数是相等的，此时可以将其看成是类似与svm中的margin，所以可以理解为每轮寻找适当的g(t)，使得Z变小<strong>（这里，李航老师给出了证明：adaboost的训练误差是小于所有轮权重和的乘积的，每轮的优化方向也是使得当前轮的Z最小）</strong>；  </p><p><strong>b.</strong> 利用梯度下降的思想，把函数看成向量，也就是说再向量空间里，先找到最好的更新函数，也就是该函数的负梯度方向，再寻找最优的下降步长；</p><p>此外，对于adaboost需要注意的是：<br>当每轮的g(t)的误分概率小于0.5时，其训练误差可以以指数速率下降。  </p><p>这里李航老师根据训练误差上界继续推导即可得证，而林轩田老师则是以VC bound角度来看，经过O(logN)轮次迭代，训练误差将会减小到0的程度。</p><p><strong>缺点：</strong>  对异常样本敏感，异常样本在迭代中可能会获得较高的权重，影响最终的强学习器的预测准确性。  </p><p><strong>优点：</strong> Adaboost作为分类器时，分类精度很高，作为简单的二元分类器时，构造简单，结果可理解。不容易发生过拟合  </p><p><strong>可以看出，boosting方法主要是减少模型的偏差。</strong></p><h3 id="（3）Decision-Tree"><a href="#（3）Decision-Tree" class="headerlink" title="（3）Decision Tree"></a>（3）Decision Tree</h3><p>为什么说Decision Tree对应的conditional条件的aggregation？  </p><p>简单来讲，对于任意一颗决策树，把每条路径看成是Qt(x)，与之对应的叶子节点看成是Gt(x)，那么该决策树就可以表示成的conditional条件的aggregation，具体如下：  </p><p><img src="http://pb0xohu5g.bkt.clouddn.com/18-7-26/6288396.jpg" alt="">  </p><p><strong>缺点：</strong> 预测结果缺乏平滑性，不适合处理高维稀疏数据  </p><p><strong>优点：</strong> 可解释性强、可处理混合类型特征、 具体伸缩不变性（不用归一化特征）、 有特征组合的作用、可自然地处理缺失值、对异常点鲁棒、有特征选择作用、可扩展性强，容易并行  </p><p>常见的决策树算法有ID３、C４.５和CART,具体的算法细节和注意点在另一篇文章中可以看到。（点此处）</p><hr><h2 id="3-集成学习的高阶实现"><a href="#3-集成学习的高阶实现" class="headerlink" title="3.集成学习的高阶实现"></a>3.集成学习的高阶实现</h2><p>从上面的讨论可以看出bagging主要是减少模型的方差，而boosting主要是减少模型的偏差，尝试将多个模型、策略再次组合，可以得到更加强健的模型。  </p><h3 id="（1）Random-Forest"><a href="#（1）Random-Forest" class="headerlink" title="（1）Random Forest"></a>（1）Random Forest</h3><p>将bagging与Decision Tree结合，就得到了Random Forest。<br>此处的bagging是bagging in everywhere：一是在抽取数据时用了Bagging(这里也导致了其另一个优良性：无需额外交叉验证)；二是在构建每一个决策树时，随机抽取一部分特征，起到了特征转换的作用；三可以用数组p进行线性组合，来保持特征多样性。  </p><p>两个特性：<br>第一，无需额外的交叉验证，用oob样本对应的决策树的平均预测值近似地代表最终预测值，通过该值的误差平方和近似地表示，最后模型的预测能力。可以证明oob（out  of bag）样本占比约为1/e;  </p><p>第二，通过random test进行特诊筛选（random test的思路是对于某个特征，用随机值代替原值，比较代替前后的模型表现，若无影响，则可以忽略），一般有两种方式进行random test，一时用已知的随机分布例如高斯分布去代替，二是将该特征的原始值进行打乱重排，也就是permutation test（随机排序测试）。后者显然更科学，因为没有改变原始分布情况。random forest为了减少计算量，直接对比oob样本的ermutation test后的模型表现，做出特征筛选。</p><p><strong>缺点：</strong>  随机森林在解决回归问题时，并没有像它在分类中表现的那么好，这是因为它并不能给出一个连续的输出。当进行回归时，随机森林不能够做出超越训练集数据范围的预测，这可能导致在某些特定噪声的数据进行建模时出现过度拟合。（PS:随机森林已经被证明在某些噪音较大的分类或者回归问题上回过拟合）。  </p><p>对于小数据或者低维数据（特征较少的数据），可能不能产生很好的分类。  </p><p><strong>优点：</strong> 随机森林算法有很强的抗干扰能力：对于不平衡数据集来说，随机森林可以平衡误差。如果有很大一部分的特征遗失，用RF算法仍然可以维持准确度。  </p><p>随机森林抗过拟合能力比较强：对generlization error(泛化误差)使用的是无偏估计模型。  </p><h3 id="（2）GBDT、XGboost、LightGBM以及Catboost"><a href="#（2）GBDT、XGboost、LightGBM以及Catboost" class="headerlink" title="（2）GBDT、XGboost、LightGBM以及Catboost"></a>（2）GBDT、XGboost、LightGBM以及Catboost</h3><h5 id="GBDT"><a href="#GBDT" class="headerlink" title="GBDT"></a>GBDT</h5><p>具体得算法步骤如下：  </p><p><img src="http://pb0xohu5g.bkt.clouddn.com/18-7-26/23486876.jpg" alt="">  </p><p>取g(t)为cart决策回归树时，就是GBDT了。当损失函数为误差平方和时，解决的时回归问题，当损失函数时Log-Likehood 是，解决的是分类问题。  </p><p>注意：每次更新的g(t)是损失函数的负梯度方向（利用了损失函数一阶导数信息）。  </p><p><strong>缺点：</strong>  boosting是个串行的过程，所以并行麻烦，需要考虑上下树之间的联系，计算复杂度大，不适合高维稀疏特征</p><p><strong>优点：</strong> 能适应多种损失函数，不需要做特征的归一化，可以自动选择特征，模型可解释性好等等</p><h5 id="XGboost"><a href="#XGboost" class="headerlink" title="XGboost"></a>XGboost</h5><p>XGboost可以看作时GBDT的高效的实现版本，相比于GBDT其损失函数中添加了正则项：对每棵树的复杂的进行了惩罚，具体如下所示：  </p><p><img src="http://pb0xohu5g.bkt.clouddn.com/18-7-27/91427960.jpg" alt="">  </p><p>此外，在优化目标函数时，使用了其二阶导数的信息，也就是牛顿法求最小（二阶泰勒展开）。</p><p>关于XGboostd的详细问题，例如树结构确定方法（贪心法）、打分函数、树节点分裂方法、稀疏值处理、行采样、列采样、学习率（Shrinkage）、 支持自定义损失函数（需二阶可导）等，可在这里查看（插个眼）  </p><p><strong>注意：</strong>XGBoost无法单独处理分类特征，它是基于CART的，所以只接收数值。在把分类数据提供给算法前，我们先得执行各种编码，如标签编码、均值编码、独热编码等。  </p><p>LightGBM与XGBoost相比，速度更快，内存占用更低。<br>改进的地方：利用直方图算法减小内存占用和计算增益的计算量、建树过程优化Leaf-wise（基于梯度的单侧采样（GOSS）不依赖剪枝）、并行优化（特征并行【避免广播instance indices，减小网络通信量，但单个worker运算代价高】、数据并行【直方图算法，减少通信量】）  </p><p>catboost和LightGBM类似，更适合处理含有分类特征的数据，CatBoost在分类变量索引方面具有相当的灵活性，它可以用在各种统计上的分类特征和数值特征的组合将分类值编码成数字（one_hot_max_size：如果feature包含的不同值的数目超过了指定值，将feature转化为float）。LightGBM也可以通过输入特征名称来处理分类特征。它无需进行独热编码（one-hot coding），而是使用一种特殊的算法直接查找分类特征的拆分值，最后不仅效果相似，而且速度更快。  </p><p>以下列出三者部分参数的区别：  </p><p><img src="http://pb0xohu5g.bkt.clouddn.com/18-7-27/69726618.jpg" alt="">  </p><p>（来源于互联网，图侵删）</p><p>以上是本文的全部内容，学的都是些皮毛，肯定存在很多错误，欢迎讨论指教！  </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;前言&lt;/strong&gt;：以下内容主要是本人在学习台大林轩田机器学习技法课程中模型融合部分以及《统计学习方法》相关内容的学习心得，且不涉及公式推导和证明部分。  &lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&quot;1-集成学习的动机与框架&quot;&gt;&lt;a href=&quot;#1-集成学习的
      
    
    </summary>
    
      <category term="机器学习" scheme="http://dzrx1020.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="集成学习" scheme="http://dzrx1020.com/tags/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="boosting" scheme="http://dzrx1020.com/tags/boosting/"/>
    
      <category term="bagging" scheme="http://dzrx1020.com/tags/bagging/"/>
    
  </entry>
  
</feed>
